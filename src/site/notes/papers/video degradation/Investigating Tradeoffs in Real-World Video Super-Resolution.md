---
{"dg-publish":true,"permalink":"/papers/video degradation/Investigating Tradeoffs in Real-World Video Super-Resolution/"}
---

Kelvin C.K. Chanm,  Shangchen Zhou, Xiangyu Xu, Chen Change Loy
—— 南洋理工大学 S-lab


![Pasted image 20240228150101.png](/img/user/asserts/Pasted%20image%2020240228150101.png)
> Figure1. 作者研究了在现实世界中视频由于复杂和不同的退化带来的问题。

# Abstract

在真实世界的视频超分辨率（VSR）中，各种复杂的退化现象给推理和训练带来了挑战。首先，尽管长期传播在轻微退化情况下有助于提高性能，但在野外严重退化情况下，通过传播可能会夸大退化，从而损害输出质量。==为了平衡细节合成和伪影抑制之间的权衡，我们发现**图像预清洁**阶段是必不可少的，以在传播之前减少噪声和伪影==。配备精心设计的清洁模块，我们的RealBasicVSR在质量和效率方面均优于现有方法（图1）。其次，真实世界的VSR模型通常使用多样化的退化进行训练，以提高泛化能力，这需要增加批量大小以产生稳定的梯度。不可避免地，增加的计算负担会导致各种问题，包括1）速度-性能权衡和2）批量长度权衡。==为了缓解第一个权衡，我们提出了一种随机退化方案，可以减少高达40% 的训练时间而不损失性能。==然后，我们分析了不同的训练设置，并建议在训练过程中使用更长的序列而不是更大的批次，可以更有效地利用时间信息，从而在推理过程中实现更稳定的性能。为了促进公平比较，==我们提出了新的VideoLQ数据集，其中包含丰富纹理和图案的大量真实世界低质量视频序列。==我们的数据集可以作为基准测试的共同基础。代码、模型和数据集可以在 https://github.com/ckkelvinchan/RealBasicVSR 上公开获取。
# Introduction
在真实世界的视频超分辨率（VSR）中，我们的目标是提高包含未知退化的视频的分辨率。在这一任务中，退化的多样性给设计基准和训练设置带来了重大挑战，因此早期的研究假设使用合成[4, 6, 35]或特定相机[41]的退化，并专注于网络设计。尽管这些研究在受限制的设置中取得了显著成功，但针对这些过度简化的场景设计的模型无法很好地推广到复杂的真实世界退化情况。此外，真实世界VSR中退化的复杂性和多样性引入了额外的障碍，包括伪影放大和增加的计算预算。本文深入探讨了真实世界VSR中的问题和权衡，以分享在解决这一任务中的有用经验。

Chan等人[4]指出，长期信息对恢复是有益的。然而，在真实世界的VSR中，这种信息也可能导致伪影夸大，这是由于在传播过程中误差的累积。这种现象导致了增强细节和抑制伪影之间的权衡，因为网络的合成能力是以放大噪声和伪影为代价的。在这项工作中，我们展示了一个简单的解决方案可以充分弥补这种权衡。具体来说，我们**在传播之前放置了一个图像清洁模块，用于去除输入图像中的退化**。由此产生的模型RealBasicVSR避免了伪影的放大，并在保持简单性的同时实现了改善的输出质量。我们进一步开发了**一个动态细化方案，该方案反复应用清洁模块以去除输入中的过度退化**。我们的方案允许在平滑性和详细性之间灵活权衡，可以根据预定义的阈值或用户偏好进行调整。我们对不同损失和架构组合进行了系统分析，以展示我们设计的重要性。

**真实世界的VSR模型通常使用多样的退化进行训练，以提高泛化能力，因此它们通常使用增大的批量大小来确保稳定的梯度**。因此，真实世界的VSR通常需要比非盲目对应物更长的训练时间和更庞大的计算资源。本研究检查了真实世界VSR中的两种权衡，以提高训练效率，从而缩短研究周期。
首先，随着批量大小的增加，由于硬件限制引起的I/O瓶颈，使用长序列进行训练是不可取的。这种瓶颈通常通过减小批量大小或序列长度来缓解，但这会导致性能下降。==为了改善这个问题，我们提出了一种随机退化方案，可以有效减少I/O瓶颈，同时不牺牲输出质量。值得注意的是，与传统训练方案相比，我们的退化方案可以将训练时间缩短高达40%。==
第二，在固定的计算预算下，真实世界视频超分辨率中增大的批量大小不可避免地会在训练过程中减少序列长度。我们对它们之间的权衡感兴趣，旨在寻找更有效的设置。为此，我们比较了使用不同批量大小和序列长度组合进行训练的模型。我们得出结论，==与更大的批量相比，使用较长序列进行训练的网络可以更有效地利用输入序列中的长期信息，提高稳定性。==

除了上述研究，我们还引入了一个新的用于真实世界视频超分辨率的基准测试。大多数现有的基准测试[25, 32, 40, 42]是通过在高分辨率（HR）视频中引入预定义的降级来构建的。最近的RealVSR数据集[41]利用iPhone的双摄系统捕获配对数据。然而，RealVSR数据集仅包含针对iPhone相机的降级。由于只有预定义的降级，上述基准测试无法准确反映模型在真实世界视频上的泛化能力。在这项工作中，==我们提出了VideoLQ，这是一个由多样的低分辨率视频组成的真实世界视频数据集，涵盖了各种内容、分辨率和降级。==我们的数据集可以作为未来方法的通用基准测试。我们在我们的数据集上测试了现有的方法。他们的定量和定性结果以及我们的数据集将被发布，以便未来的研究使用。

---
# Related Work
## Video Super-Resolution
大多数现有的视频超分辨率（VSR）方法[2, 4–6, 15–17, 19, 35, 39–41]是使用预定义的降级进行训练（例如，合成的[25, 32, 40, 42]或特定相机的[41]），当处理现实中的未知降级时，它们的性能显著下降。然而，从非盲目的VSR扩展到真实世界的VSR是非常困难的，因为野外复杂降级引发了各种问题。例如，长期传播过程中的伪影放大限制了现有VSR方法的性能，而增加的计算成本延长了研究周期。在这项工作中，我们研究了推理和训练中的挑战，并提供了相应的解决方案来应对这些挑战。

## Real-World Super-Resolution
从合成设置[3, 8–10, 37, 45]延伸而来，盲目超分辨率[12, 14, 18, 23, 24, 27, 39]假设输入是通过已知过程但未知参数引起的降级。网络使用预定义的一组降级进行训练，其中参数是随机选择的。虽然训练后的网络能够恢复具有一定范围降级的图像/视频，但降级的变化通常受限，对真实世界降级的泛化能力存在疑虑。

最近的两项研究[36, 44]提出在训练过程中采用更多样化的降级进行数据增强。这两种方法使用ESRGAN [38]，并且在架构上没有进行改变，在真实世界图像中展现出了令人期待的性能。然而，我们发现在真实世界的视频超分辨率中，这种直接的数据增强方法并不可行，因为网络往往会放大噪音和伪影。在这项工作中，我们调查了这一原因，并提出了一个简单而有效的图像清理模块来解决这个问题。配备了清理模块的RealBasicVSR在质量和效率上均优于现有的作品，包括[36, 44]。

## Input Pre-processing.
在这项研究中，我们发现一个看似微不足道的图像清理模块在传播之前去除降级并抑制输出中的伪影是至关重要的。这种优点在存在长期传播时更加显著。在单图超分辨率中，类似的概念[21, 26, 29, 34, 43]已经在无监督设置中进行了讨论。尽管在无监督范式中取得成功，但在监督设置和视频超分辨率中的输入预处理并未被探讨。与上述作品相反，我们专注于一个完全不同的监督视频超分辨率设置，以消除在长期传播过程中被放大的降级。此外，我们设计了一种动态的细化方案，在以往的作品中并未被探索，通过在推理过程中反复应用清理模块来消除过多的降级。我们还对我们的图像清理模块和细化方案进行了系统分析，以验证其有效性并为未来研究提供见解。

---

# Tradeoff in Inference
## Motivation
视频超分辨率网络通过从多个帧中聚合信息来增强细节并提高感知质量。但是，在面对未知的降级情况时，网络可能无法区分不需要的伪影和有利的细节。因此，这些伪影和噪音通过时间传播得到增强。为了验证我们的假设，我们重新对Real-ESRGAN [36]进行了实际视频超分辨率的训练。Real-ESRGAN接受任意长度的序列，这使我们能够通过调整序列长度来探索时间传播的影响。我们使用了Real-ESRGAN [36]中在实际单图超分辨率中表现有效的降级方案和设置对BasicVSR进行训练。
![Pasted image 20240521122630.png](/img/user/Pasted%20image%2020240521122630.png)
> 图2 长序列传播的影响。当使用长序列信息在非盲VSR时，提升了模型性能；而在真实世界场景下会导致不需要的伪影。$L$表示了序列长度

如图2（左）所示，在非盲设置下，当序列长度L增加时，BasicVSR能够通过长期传播聚合有用信息，从而在输出中生成更多细节。相比之下，在实际视频超分辨率中，虽然传播有助于增强轻微降级情况下的细节，但从图2（右）可以观察到，通过更长序列的传播可能会放大噪音和伪影。例如，当仅使用一个帧来恢复序列时，BasicVSR能够去除输入中的噪音并产生平滑的输出，但是在整个序列上进行传播会导致输出出现严重的伪影。

## Input Pre-Cleaning for Real-World VSR
受上述启发，我们提出了一个简单的插件，用于在时间传播之前抑制降质。其高层思想是“清洁”输入序列，使输入中的降质对后续的视频超分辨率网络产生较弱的影响。尽管在概念上简单，但模块的设计需要特别谨慎。有关我们清洁模块的更多分析可在第3.3节中找到。
### Fromulation
![Pasted image 20240521123530.png](/img/user/Pasted%20image%2020240521123530.png)
> 图3. RealBasicVSR的概述。首先，输入图像被独立传递到我们的图像清洁模块。然后，干净的序列被传递到VSR网络（即BasicVSR [4]）。请注意，整个网络是端到端训练的。

图像清洁模块用于在BasicVSR [4]之前。输入图像首先被独立地传递给清洁模块以去除降质。设xi为输入序列的第i个图像，C为我们的图像清洁模块，有
$$
\tilde{x}_i = C(x_i)\tag{1}
$$
清洁后的序列送入到VSR网络$S$用于超分辨率：
$$
\{y_i\} = S(\{\tilde{x_i}\}). \tag{2}
$$
我们在这项工作中采用了BasicVSR [4]，因为它在非盲目的视频超分辨率中表现出很好的性能，通过长期传播实现，而且其架构简单。
为了指导图像清洁模块，我们用低分辨率的真实值约束清洁模块的输出：
$$\mathcal{L}_{\text{clean}} = \sum_i\rho(\tilde{x}_i-d{z_i}), \tag{3}$$
这里，$z_i$是地面真实高分辨率图像，$d$是一个下采样算子(pytorch中的`area`模式)。在这里，ρ代表Charbonnier损失[7]。除了清洁损失外，我们还使用输出保真度损失来指导清洁模块。
> Charbonnier loss
> $\text{Charbonnire Loss} = \sqrt{(y_i - \hat{y}_i)^2 + \epsilon^2}$ 
> $\text{L1 Loss} = \sum^n_{i=1}|y_i-\hat{y}_i|$ 
> $\text{L2 Loss }=\sum^n_{i=1}(y_i - \hat{y}_i)^2$

请注意，当我们使用感知损失[20]和对抗损失[11]对网络进行微调时，清洁模块不会接收梯度。

### Dynamic Refinement
在许多具有挑战性的情况下，仅仅将输入一次传递给清洁模块无法有效地去除过多的退化。一个简单而有效的方法是通过再次传递给清洁模块来进一步抑制退化。形式上，我们设计了一个在测试时动态移除退化的改进方案：
$$
\left\{  
             \begin{array}{**lr**}  
             \tilde{x}^{j+1}_i=C(\tilde{x}^j_i), & \text{if } \mathcal{maen}(|\tilde{x}^j_i-\tilde{x}^{j-1}_i|) \ge \theta,  \\  
             \tilde{x}_i=\tilde{x}^j_i, & \text{otherwise}, \\    
             \end{array}  
\right. \tag{5}
$$

其中$\tilde{x}^0_i$，θ是一个预先确定的停止准则。我们发现，对于非基于GAN的模型，θ=1.5是一个合理的设置；对于基于GAN的模型，θ=5是一个合理的设置。

### Architecture.
在这项工作中，==我们简单地使用了一堆残差块[13]作为清洁模块==。值得注意的是，虽然我们的清洁模块在概念上很简单，但它不能采用任意设计，我们将在第3.3节中讨论。在我们的设计中，VSR网络的伪影抑制作用由清洁模块共同承担，因此可以采用一个更轻的VSR网络。在我们的实验中，我们将BasicVSR中的残差块数量从60减少到40，以保持可比较的复杂性。

## Analysis of Input Pre-Cleaning
### Designs.
![Pasted image 20240521143453.png](/img/user/Pasted%20image%2020240521143453.png)
> 图4. 清洁模块分析。所提出的清洁损失在去除伪影中起着重要作用。清洁模块的设计需要特别小心。采用循环结构的另一种模型未能去除伪影。（放大以获得最佳视图）


我们研究了所提出的图像清洁损失和清洁模块的架构对结果的影响。图4展示了一些实验结果示例。
首先，我们训练RealBasicVSR，去除图像清洁损失（公式（3））。当损失被移除时，RealBasicVSR可以被视为一个单阶段网络，就像BasicVSR一样。该网络夸大了噪声和伪影，原始内容被扭曲，这表明图像清洁损失的重要性。请注意，可以采用其他的损失函数，如对抗性损失和感知损失，但我们发现最简单的像素级损失已经足够了。
其次，我们保留图像清理损失，并用一个循环网络替换我们的清理模块。即使有清理损失，网络仍无法去除不需要的降质，也导致输出失真。这一观察结果与我们的假设一致，即基于视频的网络倾向于通过聚合夸大伪影，这表明采用基于图像的网络作为清理模块的重要性。与前述变体相比，我们的设计产生更加平滑的输出，并保留更多图像内容。

### Dynamic Refinement.
![Pasted image 20240521145134.png](/img/user/Pasted%20image%2020240521145134.png)
>图5. 动态细化效果。我们的动态细化方案会自动停止清洁过程，以避免过度平滑和异常平坦的区域。更多示例请参考补充材料。（放大查看最佳效果）


在图5中，我们展示了使用我们的动态细化方案的一个示例。一方面，当仅应用清洁模块一次时，尽管显示了更多的细节，噪音仍然无法完全消除。另一方面，观察到当清洁模块应用五次时，输出结果变得异常平坦，细节消失。相比之下，使用我们的动态细化方案，清洁阶段会自动停止以避免过度平滑。我们发现输出结果包含较少的人工痕迹，同时保留了必要的细节。我们观察到在大多数情况下最多只需要三次迭代。

![Pasted image 20240521151106.png](/img/user/Pasted%20image%2020240521151106.png)
> 图6. 细化消融实验。 (a) 使用我们的动态细化方法，NIQE显著降低。阈值控制着细节级别，导致不同的NIQE。 (b) 我们的动态细化方案获得比固定迭代更好的NIQE。NIQE是在我们的VideoLQ数据集上计算的。

我们接着研究了图6(a)中阈值θ的影响。首先，我们的动态细化方案使得我们所使用的所有阈值的NIQE显著降低。其次，观察到不同阈值选择导致不同细节级别，因此导致不同的NIQE。在图6(b)中，我们将我们的方案与固定迭代次数进行了比较。我们的动态细化方案确定了特定于图像的阈值，从而提高了性能。值得注意的是，可以设计更复杂的决策过程，或者手动确定清理模块的通道数。我们将更详细的细化方案设计留作今后的工作。

---
# Tradeoff in Training
在真实世界的视频超分辨率中，网络需要处理各种不同的退化，因此它们通常会使用多种退化进行训练。因此，这些网络通常会使用增加的批处理大小来产生稳定的梯度。因此，训练真实世界的视频超分辨率网络通常需要比非盲目的对应物更多的计算资源。在这项工作中，我们深入探讨了增加的计算预算所带来的两个挑战，即1) 速度和性能的权衡，以及2) 批处理长度的权衡。
## Training Speed vs. Performance
当使用批处理大小B和序列长度L进行训练时，CPU需要在每次迭代中加载B×L张图像。在真实世界的视频超分辨率中，增加B会引入严重的I/O瓶颈，大大减慢训练速度。通常，通过减少批处理大小或序列长度来规避瓶颈，但会导致性能下降。==在这项工作中，我们提出了一种随机退化方案，显著提高了训练速度而不损害性能==。图7显示了L=4的图形说明。
![Pasted image 20240521151922.png](/img/user/Pasted%20image%2020240521151922.png)
> 图7. 随机退化方案。通过每次迭代加载更少的帧并使用随着时间变化的退化，我们的随机退化方案在不损害性能的情况下减少了40%的训练时间。每个圆代表一个视频帧，$p_i = p_{i−1} + r_i$。

在我们的随机退化(Stochastic)方案中，我们不是在每次迭代中加载L帧，而是加载L/2帧并在时间上翻转序列。这种设计使我们能够在减少CPU工作量的同时，使用相同长度的序列进行训练。然而，在这样的设置中，网络感知到的内容变化较小，并且网络可能会潜在地利用序列在时间上翻转的快捷方式。为了提高数据的多样性，我们将每帧的退化建模为随机游走。具体地，设pi为应用于第i帧的退化对应的参数，则我们有$p_{i+1} = p_i + r_{i+1}$，其中$r_{i+1}$表示第(i+1)帧和第i帧的参数之间的差异。

![Pasted image 20240521152538.png](/img/user/Pasted%20image%2020240521152538.png)
> 图8. 使用随机退化的结果。直接翻转序列导致性能下降，而应用我们的随机退化方案则使性能提高，训练时间减少了高达40%。


如图8所示，与传统训练方案相比，~~直接翻转序列在质量上导致了类似或降低的性能~~。例如，由于输入中的混叠效应，线条图案的方向发生了扭曲。当应用我们的随机退化方案时，网络对退化变化更加鲁棒，从而提高了性能。此外，如表1所示，通过减少处理的图像数量，CPU的工作负荷显著减轻。因此，I/O瓶颈得到改善，训练时间缩短了高达40%，而性能却没有受到影响。
![Pasted image 20240521152654.png](/img/user/Pasted%20image%2020240521152654.png)
> 表1. 与随机退化方案的比较。我们的方案在保持可比性能的同时，训练时间减少了40%。

## Batch Size vs. Sequence Length
~~在固定的计算预算下，训练真实世界的视频超分辨率模型时，增加批处理大小不可避免地导致序列长度的减少。~~一方面，使用更大的批处理大小使网络能够在每次迭代中感知更多的退化和场景内容，从而产生更稳定的梯度。另一方面，使用更长的序列训练使网络能够更有效地利用长期信息。然而，在计算资源有限的情况下，必须在更大的批处理和更长的序列之间做出选择。我们对它们之间的权衡感兴趣，旨在为未来的工作提供有效的设置。在本节中，我们在B×L=480的约束条件下训练RealBasicVSR，并讨论这些模型的性能。我们使用了我们的随机退化方案。
![Pasted image 20240521181846.png](/img/user/Pasted%20image%2020240521181846.png)
> **图9. 批处理和序列长度之间的权衡**。在固定的计算约束条件下，使用较大的批处理大小和较短的序列训练会导致色彩伪影和输出模糊。令人惊讶的是，当序列长度较小时，使用较大的批处理大小会损害性能。

如图9所示，当使用B=48，L=10进行训练时，观察到输出包含严重的色彩伪影和失真细节。当我们增加序列长度时，这种不良效果会减少。特别是，当L从10增加到20时，色彩伪影显著减少，当L增加到30时进一步消除了这些色彩伪影。
上述比较表明，==使用更长的序列进行训练更为可取==。我们推测，使用短序列训练的网络在推断过程中无法适应长序列，这是由于训练和推断之间的领域差异所致。为了进一步证明训练中长序列的重要性，我们将B固定为16，并将L从30减少到10。观察到，当减少L时，相应区域显示出相同的色彩伪影和模糊。因此，建议在受到计算约束时使用更长的序列。

---
# VideoLQ Dataset and Benchmark
为了评估真实世界的视频超分辨率方法的泛化能力，一个涵盖各种降级、内容和分辨率的基准测试是不可或缺的。大多数现有数据集[25,32,40,42]仅关注于合成降级，如双三次下采样，因此它们无法反映真实世界视频超分辨率方法的有效性。最近的RealVSR数据集[41]包括了由iPhone双摄系统拍摄的LR-HR视频对。尽管这些数据不是通过合成降级构建的，但这些序列是由单摄像头拍摄的，因此LR视频仅包含特定于摄像头的降级。因此，并不能保证在RealVSR数据集中表现优越的方法能够推广到真实世界的视频。

在这项工作中，我们提出了VideoLQ数据集。视频示例如图10所示。我们的VideoLQ数据集中的视频是从Flickr和YouTube等各种视频托管网站下载的，具有创意共享许可证。为了确保视频的多样性，我们选择了不同分辨率和内容的视频，以涵盖尽可能多的降级情况。对于每个视频，我们提取了一个包含100帧的序列，不允许场景变化，以便评估依赖长期传播的方法。所选序列包含足够的纹理或文本以便于比较。此外，Vid4数据集[25]中的真实视频也被包括在内。
![Pasted image 20240521182542.png](/img/user/Pasted%20image%2020240521182542.png)
> **图10. VideoLQ数据集**。我们的VideoLQ数据集包括了从Flickr和YouTube等不同视频托管网站收集的具有多样内容和分辨率的视频。它可以作为未来比较的共同基准。

## Experimental Settings
我们在我们的VideoLQ数据集上进行了实验。我们将我们的RealBasicVSR与七种最先进的方法进行了比较，包括四种图像模型：RealSR [18]，DAN [27]，RealESRGAN [36]，BSRGAN [44]，以及三种视频模型：BasicVSR++3 [6]，RealVSR [41]，DBVSR [33]。更多讨论详见补充材料。

## Training Degradations
在Real-ESRGAN [36]之后，我们采用了二阶降级模型，并应用随机模糊、调整大小、噪声和JPEG压缩作为基于图像的降级。此外，我们还结合了视频压缩，这是一种常见的减小视频大小的技术。与前述的降级不同，视频压缩隐含考虑了视频帧之间的相互依赖关系，为我们提供了在时间和空间上变化的降级。我们在训练过程中使用随机选择的编解码器和比特率进行压缩，并观察到包含视频压缩时的性能提升。具体设置详见补充材料。对于比较中的方法，我们使用它们公开可用的代码。

## Training Settings.
在DBVSR [33]之后，我们使用REDS数据集 [32] 进行训练。我们采用Adam优化器 [22] 以恒定的学习率。输入LR帧的块大小为64×64。我们采用了时长为30(每次迭代cpu加载15张图像)的随机降级方案。训练分为两个阶段：首先，我们仅使用输出损失和图像清理损失对RealBasicVSR进行了30万次迭代的预训练，批量大小为16，学习率为10^-4。然后，我们对网络进行了15万次迭代的微调，同时加入了感知损失 [20] 和对抗损失 [11]。批量大小减小为8。生成器和鉴别器的学习率分别设置为5×10^-5和10^-4。

## Architecture
在对抗训练中，我们将RealBasicVSR作为生成器，并采用Real-ESRGAN的鉴别器。对于生成器，我们的图像清理模块C由20个残差块组成。我们使用BasicVSR作为我们的VSR网络S，残差块的数量设置为40。特征通道的数量为64。详细的实验设置和模型架构请参见补充材料。